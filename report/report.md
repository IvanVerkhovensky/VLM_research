# VLA for manipulation: grounding языка и OOD-устойчивость — мини-аудит на SmolVLA

Контекст - трек VLA for manipulation: multi-skill, long-horizon, robustness, embodiment-agnostic.  
 я сделал воспроизводимый аудит публичной VLA-политики и использовал его как доказательство цифры и графики для формулировки открытой проблемы и гипотезы решения.

---

## 1) Свежие работы 2022–2025 на которые я опирался

Я выбирал так чтобы показать VLA как класс моделей, масштабирование и перенос, смесь embodiment и открытые пайплайны.

- RT-2 (2023) — пример VLA в современном смысле -  перенос vision-language представлений, включая web-knowledge в робот управление. Нужен для ориентации по семантической генерализации и постановке задач.
- Open X-Embodiment / RT-X (2024) — большой шаг к embodiment-agnostic - единый формат данных и обучение на смеси роботов. Хорошо показывает что многие проблемы лежат в данных и распределениях и несовпадении observation/action spaces.
- Octo (2024) — открытая generalist policy, полезна как  baseline и как пример практической адаптации к новым сенсорам.
- OpenVLA (2024) — открытая VLA-модель и инженерные оценки и дообучения, снижает проблемы воспроизводимости.
- SmolVLA + LeRobot (2025) — компактная VLA-политика и tooling которые запускаются на consumer hardware в моём случае  MacBook.

---

## 2) Открытая проблема 

Даже современные VLA политики могут быть одновременно:

1) Слабо привязаны к языку - инструкция влияет на действие, но не всегда предсказуемо — модель может частично ездить на визуальном контексте, а язык становится слабым модификатором.

2) хрупкими к небольшим визуальным OOD сдвигам - изменения освещения, шум сенсора, частичная окклюзия — это нормально в реальном мире, но они могут сильно менять предсказанные действия.

В long horizon и multi skill сценариях эти эффекты накапливаются и превращаются в нестабильное выполнение.

---

## 3) Гипотеза преодоления барьера

Гипотеза в следующем -  если при fine tuning/post training добавить два вида регуляризации, то можно одновременно улучшить instruction-following и OOD-устойчивость без сильного роста данных:

- Counterfactual language contrast - для одного наблюдения подать конфликтующие инструкции и штрафовать модель, если действия почти не различаются - усиливать предсказуемую зависимость от языка.
- Visual consistency regularization - для допустимых perturbations, brightness/noise/occlusion в разумных пределах, штрафовать высокий action drift чтобы уменьшать хрупкость к OOD.

Я не делал полный fine-tune с этими регуляризаторами из за нехватки времени. Вместо этого я построил и провёл корректный baseline аудит, который:
- показывает, что проблема измерима на публичном baseline,
- задаёт воспроизводимый протокол до и после для проверки гипотезы на следующем шаге.

---

## 4) воспроизведение/измерения

Модель: HuggingFaceVLA/smolvla_libero  
Датасет (LeRobot v3.0): eunyoung927/smol-libero-v30  
Железо: MacBook, Apple MPS

Я сделал два офлайн-аудита:

### 4.1 Language sensitivity audit
Для одного и того же наблюдения сравниваю предсказанные действия при:
- исходной инструкции
- пустой инструкции
- противоречивой инструкции

Метрика: L2(action_orig - action_variant).

### 4.2 OOD visual sensitivity audit
Для тех же наблюдений вношу perturbations в изображения обеих камер:
- brightness
- gaussian noise
- occlusion

И измеряю дрейф действий относительно исходного.

### 4.3 очереди действий + детерминизм

SmolVLA использует action chunking/внутренние очереди, поэтому повторные вызовы select_action() могут возвращать разные действия даже на одном и том же входе.  
Чтобы сравнение отражало именно влияние входа (язык/картинка), я:
- сбрасываю состояние политики перед каждым предсказанием,
- фиксирую seed “на фрейм” одинаково для orig/variant.

Контроль качества протокола: mean_dist_repeat ≈ 0.

---

5) Результаты
Графики:

figures/language_sensitivity.png
figures/ood_sensitivity.png
JSON:
outputs/language_seed*.json
outputs/ood__seed.json

5.1 Язык (120 фреймов, seed=0)
repeat drift: 0.0
mean drift (empty instruction): ~0.779
mean drift (counterfactual/shuffle): ~0.704
(Смысл такой - язык влияет на предсказания измеримо, при этом протокол детерминирован, то есть это не шум.)

5.2 OOD JSON и график
Визуальные perturbations (яркость/шум/окклюзия) дают измеримый action drift. Это прокси метрика не success-rate, но она хорошо показывает наличие сигнала неустойивого к OOD.

6) Что бы я делал дальше развивая эту идею
Success-rate eval в симуляции (LIBERO или аналог) + controlled perturbations, чтобы связать action drift с реальным успехом/провалом задач.
Лёгкий fine-tune например LoRA baseline vs +регуляризаторы из гипотезы и сравнение до и после по тем же аудитам и по success-rate.
Отчёт mean±std по нескольким seed- часть уже сделана в моем репозитории.
